{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11f0c0df",
   "metadata": {},
   "source": [
    "During this training I want to try generating training data during the run. Architecture of the model is the same as in 20221030"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "366f7e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import normalize\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "import os\n",
    "from glob import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e366b6",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4607dc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_unet_model(n_classes=4, IMG_HEIGHT=544, IMG_WIDTH=544, IMG_CHANNELS=1):\n",
    "#Build the model\n",
    "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    s = inputs\n",
    "\n",
    "    #Contraction path\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "     \n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "     \n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "     \n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "    \n",
    "    #Expansive path \n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "     \n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "     \n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "     \n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "     \n",
    "    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9)\n",
    "     \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83d2775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE_X = 544\n",
    "SIZE_Y = 544\n",
    "n_classes = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcb95c4",
   "metadata": {},
   "source": [
    "### Image loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14626e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidpilny/miniforge3/envs/tensorflow/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dir = \"../../../../Desktop/Ateroskleroza_Data_Original_26_9_19/images/\"\n",
    "mask_dir = \"../../../../Desktop/Ateroskleroza_Data_Original_26_9_19/labels/\"\n",
    "\n",
    "train_images = []\n",
    "for directory_path in glob(input_dir):\n",
    "    for img_path in glob(os.path.join(directory_path, \"*.png\")):\n",
    "        img = cv2.imread(img_path, 0)\n",
    "        train_images.append(img)\n",
    "        \n",
    "train_images = np.array(train_images)\n",
    "\n",
    "train_masks = []\n",
    "for directory_path in glob(mask_dir):\n",
    "    for mask_path in glob(os.path.join(directory_path, \"*.png\")):\n",
    "        mask = cv2.imread(mask_path, 0)\n",
    "        train_masks.append(mask)\n",
    "\n",
    "train_masks = np.array(train_masks)\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "n, h, w = train_masks.shape\n",
    "train_masks_reshaped = train_masks.reshape(-1, 1)\n",
    "train_masks_reshaped_encoded = labelencoder.fit_transform(train_masks_reshaped)\n",
    "train_masks_reshaped_encoded_original_shape = train_masks_reshaped_encoded.reshape(n, h, w)\n",
    "\n",
    "np.unique(train_masks_reshaped_encoded_original_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "123f9d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "train_images = normalize(train_images, axis=1)\n",
    "\n",
    "train_masks_input = np.expand_dims(train_masks, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "274ca7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class values in the dataset are ... [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_images, train_masks_input, test_size = 0.10, random_state=42)\n",
    "print(\"Class values in the dataset are ...\", np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6e695d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights are ...: [ 0.3444192   2.87042313 14.82685638  1.46899924]\n"
     ]
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight(\n",
    "                                        class_weight = \"balanced\",\n",
    "                                        classes = np.unique(train_masks_reshaped_encoded),\n",
    "                                        y = train_masks_reshaped_encoded                                                    \n",
    "                                    )\n",
    "\n",
    "print(\"Class weights are ...:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93334036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 544, 544, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 544, 544, 16) 160         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 544, 544, 16) 0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 544, 544, 16) 2320        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 272, 272, 16) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 272, 272, 32) 4640        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 272, 272, 32) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 272, 272, 32) 9248        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 136, 136, 32) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 136, 136, 64) 18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 136, 136, 64) 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 136, 136, 64) 36928       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 68, 68, 64)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 68, 68, 128)  73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 68, 68, 128)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 68, 68, 128)  147584      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 34, 34, 128)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 34, 34, 256)  295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 34, 34, 256)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 34, 34, 256)  590080      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 68, 68, 128)  131200      conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 68, 68, 256)  0           conv2d_transpose[0][0]           \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 68, 68, 128)  295040      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 68, 68, 128)  0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 68, 68, 128)  147584      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 136, 136, 64) 32832       conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 136, 136, 128 0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 136, 136, 64) 73792       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 136, 136, 64) 0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 136, 136, 64) 36928       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 272, 272, 32) 8224        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 272, 272, 64) 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 272, 272, 32) 18464       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 272, 272, 32) 0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 272, 272, 32) 9248        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 544, 544, 16) 2064        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 544, 544, 32) 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 544, 544, 16) 4624        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 544, 544, 16) 0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 544, 544, 16) 2320        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 544, 544, 4)  68          conv2d_17[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,940,868\n",
      "Trainable params: 1,940,868\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "IMG_HEIGHT = X_train.shape[1]\n",
    "IMG_WIDTH = X_train.shape[2]\n",
    "IMG_CHANNELS = X_train.shape[3]\n",
    "\n",
    "def get_model():\n",
    "    return multi_unet_model(n_classes=n_classes, IMG_HEIGHT=IMG_HEIGHT, IMG_WIDTH=IMG_WIDTH, IMG_CHANNELS=IMG_CHANNELS)\n",
    "\n",
    "model = get_model()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abf11992",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 19:43:44.885075: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2023-03-21 19:43:44.885087: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2023-03-21 19:43:44.885510: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "checkpointer = ModelCheckpoint('atherosclerosis_segmentation.h5', verbose=1, save_best_only=True)\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=2, monitor='val_loss'),\n",
    "    TensorBoard(log_dir='logs')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7abe4b8",
   "metadata": {},
   "source": [
    "### Defining Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05218260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 16\n",
    "seed = 100\n",
    "\n",
    "img_data_gen_args = dict(\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      vertical_flip=True,\n",
    "      fill_mode='reflect')\n",
    "\n",
    "mask_data_gen_args = dict(\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      vertical_flip=True,\n",
    "      fill_mode='reflect',\n",
    "    )\n",
    "\n",
    "image_data_generator = ImageDataGenerator(**img_data_gen_args)\n",
    "mask_data_generator = ImageDataGenerator(**mask_data_gen_args)\n",
    "\n",
    "image_data_generator.fit(X_train, augment=True, seed=seed)\n",
    "image_generator = image_data_generator.flow(X_train, seed=seed)\n",
    "valid_img_generator = image_data_generator.flow(X_test, seed=seed)\n",
    "\n",
    "\n",
    "mask_data_generator.fit(y_train, augment=True, seed=seed)\n",
    "mask_generator = mask_data_generator.flow(y_train, seed=seed)\n",
    "valid_mask_generator = mask_data_generator.flow(y_test, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "badc806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_image_mask_generator(image_generator, mask_generator):\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    for (img, mask) in train_generator:\n",
    "        mask_cat = to_categorical(np.uint8(mask), num_classes=n_classes)\n",
    "        mask_cat = mask_cat.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2], n_classes))\n",
    "        yield (img, mask_cat)\n",
    "\n",
    "my_generator = my_image_mask_generator(image_generator, mask_generator)\n",
    "\n",
    "validation_datagen = my_image_mask_generator(valid_img_generator, valid_mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5535628",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "steps_per_epoch = 3*(len(X_train))//batch_size\n",
    "\n",
    "\n",
    "history = model.fit(my_generator, \n",
    "                    verbose=1,\n",
    "                    validation_data=validation_datagen, \n",
    "                    steps_per_epoch=steps_per_epoch, \n",
    "                    validation_steps=steps_per_epoch, \n",
    "                    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37937cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_masks_cat = to_categorical(y_train, num_classes=n_classes)\n",
    "#y_train_cat = train_masks_cat.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fbfc1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(782, 544, 544, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8d2ffc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(782, 544, 544, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_masks_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e699d4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
